
#  Pr√©diction du Risque de Maladie Cardiaque avec PySpark ML

Ce projet impl√©mente un **pipeline complet de Machine Learning** pour pr√©dire la pr√©sence de maladies cardiovasculaires √† partir de donn√©es m√©dicales. Il est construit avec **PySpark ML** et inclut toutes les √©tapes : nettoyage, EDA, feature engineering, entra√Ænement, √©valuation et interpr√©tation du mod√®le.

---

## üîπ Table des mati√®res

1. [Objectif](#objectif)
2. [Technologies et librairies](#technologies-et-librairies)
3. [Pr√©paration de l'environnement](#pr√©paration-de-lenvironnement)
4. [Chargement et exploration des donn√©es](#chargement-et-exploration-des-donn√©es)
5. [Nettoyage et recodage](#nettoyage-et-recodage)
6. [Analyse exploratoire (EDA)](#analyse-exploratoire-eda)
7. [Feature engineering et preprocessing](#feature-engineering-et-preprocessing)
8. [Construction des pipelines ML](#construction-des-pipelines-ml)
9. [Entra√Ænement et √©valuation](#entra√Ænement-et-√©valuation)
10. [Interpr√©tation des mod√®les](#interpr√©tation-des-mod√®les)
11. [Sauvegarde et utilisation du mod√®le](#sauvegarde-et-utilisation-du-mod√®le)
12. [Conclusions](#conclusions)

---

## üéØ Objectif

Pr√©dire la pr√©sence ou l‚Äôabsence d‚Äôune **maladie cardiovasculaire** √† partir de caract√©ristiques cliniques telles que :

* √Çge, Sexe
* Pression art√©rielle, Cholest√©rol, Glyc√©mie
* Fr√©quence cardiaque, ECG, Angine apr√®s effort
* Fluoroscopie, Thalass√©mie

Le mod√®le final permettra d‚Äôaider les m√©decins √† **√©valuer le risque de maladie cardiaque** rapidement.

---

## üõ† Technologies et librairies

* **Python 3.12**
* **PySpark 3.5.1** (DataFrame, MLlib)
* **Pandas / Matplotlib / Seaborn** pour la visualisation
* Mod√®les de classification PySpark : Logistic Regression, Random Forest, Gradient Boosted Trees

---

## ‚öôÔ∏è Pr√©paration de l'environnement

```bash
# Installer PySpark si n√©cessaire
pip install pyspark
```

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler
from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Cr√©er une session Spark
spark = SparkSession.builder.appName("Heart Disease Prediction").getOrCreate()
print("Spark Version:", spark.version)
```

---

## üìÇ Chargement et exploration des donn√©es

```python
df = spark.read.csv("heart-disease.csv", header=True, inferSchema=True)
df.printSchema()
df.show(5)
print(f"Nombre total de lignes: {df.count()}")
df.describe().show()
```

* Dataset : 303 patients, 15 colonnes
* Variables mixtes : num√©riques et cat√©gorielles
* Valeurs manquantes identifi√©es (`?`) et supprim√©es

---

## üßπ Nettoyage et recodage

* Recodage des variables cat√©gorielles pour plus de lisibilit√© (ex : `Sex: 0 ‚Üí Female, 1 ‚Üí Male`)
* Conversion de la variable cible en binaire (`Disease: 0 ‚Üí no, 1-4 ‚Üí yes`)
* Suppression des valeurs manquantes

```python
df_clean.show(5)
```

---

## üìä Analyse exploratoire (EDA)

* Statistiques descriptives pour variables num√©riques et cat√©gorielles
* Visualisation des distributions (histogrammes, boxplots)
* V√©rification de l‚Äô√©quilibre de la variable cible (`no ‚âà 160`, `yes ‚âà 137`)

---

## ‚ö° Feature Engineering et Preprocessing

* **StringIndexer + OneHotEncoder** pour variables cat√©gorielles
* **VectorAssembler + StandardScaler** pour variables num√©riques
* Cr√©ation de nouvelles features :

  * `Cholesterol_Blood_Pressure_Ratio`
  * `Age_BP_Interaction`
  * `BP_HeartRate_Interaction`

---

## üèó Construction des pipelines ML

* Pipeline complet pour **Logistic Regression, Random Forest, GBT**
* Label index√© avec `StringIndexer`
* Assemblage de toutes les features en vecteur final

---

## üöÄ Entra√Ænement et √©valuation

* Split train/test : 70% / 30%
* Mod√®les entra√Æn√©s : Logistic Regression, Random Forest, GBT
* Validation crois√©e (3 folds) et tuning d‚Äôhyperparam√®tres

### Exemple de m√©triques sur test set

| Mod√®le              | Accuracy | F1-score | Precision | Recall |
| ------------------- | -------- | -------- | --------- | ------ |
| Logistic Regression | 0.844    | 0.845    | 0.865     | 0.844  |
| Random Forest       | 0.818    | 0.819    | 0.848     | 0.818  |
| GBT                 | 0.805    | 0.806    | 0.830     | 0.805  |

* Matrices de confusion visualis√©es avec **Seaborn heatmap**

---

## üåü Interpr√©tation des mod√®les

* Importance des features calcul√©e pour Random Forest et GBT
* Variables les plus influentes : `Glycemia`, `BP_HeartRate_Interaction`, `Sex_encoded`

---

## üíæ Sauvegarde et utilisation du mod√®le

```python
# Sauvegarde des pipelines
model_lr.save("pipeline_lr_model.")
model_rf.save("pipeline_rf_model.")
model_gbt.save("pipeline_gbt_model.")

# Chargement et pr√©diction sur de nouvelles observations
from pyspark.ml.pipeline import PipelineModel
loaded_pipeline_lr = PipelineModel.load("pipeline_lr_model")
predictions_new = loaded_pipeline_lr.transform(new_df)
predictions_new.select("features", "prediction", "probability").show(truncate=False)
```

* Permet de pr√©dire rapidement le risque pour de **nouveaux patients**

---

## üìå Conclusions

* Pipeline PySpark complet pour pr√©diction de maladies cardiovasculaires
* Mod√®les pr√©cis, robustes et interpr√©tables
* Pr√™t pour int√©gration dans une application **de support √† la d√©cision m√©dicale**

---

## üîó Liens utiles

* [Documentation PySpark ML](https://spark.apache.org/docs/latest/ml-classification-regression.html)
* [Matplotlib](https://matplotlib.org/)
* [Seaborn](https://seaborn.pydata.org/)


